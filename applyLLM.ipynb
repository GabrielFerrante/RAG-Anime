{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda\\envs\\raganime\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [04:48<00:00, 144.44s/it]\n",
      "Some parameters are on the meta device because they were offloaded to the cpu.\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_15972\\3714368902.py:16: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Carregar modelo e tokenizador\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"deepseek-ai/deepseek-llm-7b-chat\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"deepseek-ai/deepseek-llm-7b-chat\",\n",
    "    device_map=\"auto\",  # Auto-alocação entre dispositivos\n",
    "    torch_dtype=torch.float16,  # Usa meia precisão\n",
    "    low_cpu_mem_usage=True  # Reduz uso de RAM\n",
    ")\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\"\n",
    ")\n",
    "\n",
    "vetorAnimes = FAISS.load_local('C:/Repositorios/RAG-Anime/animes_faiss_index/',embeddings,allow_dangerous_deserialization=True)\n",
    "vetorEpisodios = FAISS.load_local('C:/Repositorios/RAG-Anime/episodios_faiss_index/',embeddings,allow_dangerous_deserialization=True)\n",
    "vetorPersonagens = FAISS.load_local('C:/Repositorios/RAG-Anime/personagens_faiss_index/',embeddings,allow_dangerous_deserialization=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para gerar respostas\n",
    "def gerar_respostaComVetorAnime(query, k=2):\n",
    "   \n",
    "    docAnimes = vetorAnimes.similarity_search(query, k=k)\n",
    "\n",
    "    context1 = \"\\n\".join([doc.page_content for doc in docAnimes])\n",
    "    \n",
    "\n",
    "    # Construir prompt\n",
    "    prompt = f\"\"\"\n",
    "    Com base nas informações abaixo, responda à pergunta:\n",
    "\n",
    "    Contextos:\n",
    "    Contexto geral de animes: {context1}\n",
    "\n",
    "    Pergunta: {query}\n",
    "\n",
    "    Resposta (use markdown para destacar títulos):\n",
    "    \"\"\"\n",
    "    \n",
    "    # Gerar resposta \n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", max_length=2048, truncation=True)\n",
    "    outputs = model.generate(**inputs, max_new_tokens=200, temperature=0.7)\n",
    "    resposta = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    return resposta.split(\"Resposta:\")[-1].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:100001 for open-end generation.\n",
      "c:\\Anaconda\\envs\\raganime\\Lib\\site-packages\\transformers\\generation\\utils.py:2105: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Com base nas informaç�es abaixo, responda à pergunta:\n",
      "\n",
      "    Contextos:\n",
      "    Contexto geral de animes: 2nd Season of Gra-P &amp; Rodeo.\n",
      ".\n",
      "\n",
      "    Pergunta: cowboy bebop\n",
      "\n",
      "    Resposta (use markdown para destacar títulos):\n",
      "    \n",
      "- **Cowboy Bebop** é um anime japonês, que tem seu 2nd Season de Gra-P & Rodeo. O anime é baseado na série de mangás do mesmo nome, escrita e ilustrada por Hajime Yatate. O anime foi transmitido pela primeira vez na TV Tokyo entre 1998 e 2003, com 26 episódios.\n",
      "\n",
      "- O enredo gira em torno de três aventureiros, conhecidos como \"Cafu, Jet e Faye\", que viajam em uma nave espacial chamada \"Bebop\". A equipe se encontra em miss�es de caça a outros criminosos, enquanto lutam contra seus próprios sentimentos e passados.\n",
      "\n",
      "- O estilo artístico do anime mescla elementos\n"
     ]
    }
   ],
   "source": [
    "resposta = gerar_respostaComVetorAnime(\"cowboy bebop\")\n",
    "print(resposta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para gerar respostas\n",
    "def gerar_respostaComVetorPersonagens(query, k=2):\n",
    "   \n",
    "    docPersonagens = vetorPersonagens.similarity_search(query, k=k)\n",
    "\n",
    "    context1 = \"\\n\".join([doc.page_content for doc in docPersonagens])\n",
    "    \n",
    "\n",
    "    # Construir prompt\n",
    "    prompt = f\"\"\"\n",
    "    Com base nas informações abaixo, responda à pergunta:\n",
    "\n",
    "    Contextos:\n",
    "    Contexto geral de personagens: {context1}\n",
    "\n",
    "    Pergunta: {query}\n",
    "\n",
    "    Resposta (use markdown para destacar títulos):\n",
    "    \"\"\"\n",
    "    \n",
    "    # Gerar resposta \n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", max_length=2048, truncation=True)\n",
    "    outputs = model.generate(**inputs, max_new_tokens=200, temperature=0.7)\n",
    "    resposta = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    return resposta.split(\"Resposta:\")[-1].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:100001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Com base nas informaç�es abaixo, responda à pergunta:\n",
      "\n",
      "    Contextos:\n",
      "    Contexto geral de personagens: 2nd Season of Gra-P &amp; Rodeo.\n",
      ".\n",
      "\n",
      "    Pergunta: Personagens de cowboy bebop\n",
      "\n",
      "    Resposta (use markdown para destacar títulos):\n",
      "    \n",
      "    **Personagens Principais**\n",
      "    - **Spike Spiegel**: É o protagonista e um dos membros fundadores do Vingadores Bebop. Ele é um ex-assassino e um dos melhores tiros do mundo.\n",
      "    - **Jet Black**: É o capitão do Vingadores Bebop e o proprietário. Ele é um ex-policial que perdeu a esposa e filho em um acidente.\n",
      "    - **Ed**: É o cozinheiro do Vingadores Bebop. Ele é um alienígena e tem uma personalidade tímida e obsessiva.\n",
      "    - **Faye Valentine**: É uma mulher louca e ambiciosa que se junta ao Vingadores Bebop como uma nova membro. Ela tem habilidades de luta e é conhecida como a \"Rainha dos Roubos\".\n",
      "\n",
      "**Person\n"
     ]
    }
   ],
   "source": [
    "resposta = gerar_respostaComVetorPersonagens(\"Personagens de cowboy bebop\")\n",
    "print(resposta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para gerar respostas\n",
    "def gerar_respostaComVetorEpisodios(query, k=2):\n",
    "   \n",
    "    docEpis = vetorEpisodios.similarity_search(query, k=k)\n",
    "\n",
    "    context1 = \"\\n\".join([doc.page_content for doc in docEpis])\n",
    "    \n",
    "\n",
    "    # Construir prompt\n",
    "    prompt = f\"\"\"\n",
    "    Com base nas informações abaixo, responda à pergunta:\n",
    "\n",
    "    Contextos:\n",
    "    Contexto geral de episódios: {context1}\n",
    "\n",
    "    Pergunta: {query}\n",
    "\n",
    "    Resposta (use markdown para destacar títulos):\n",
    "    \"\"\"\n",
    "    \n",
    "    # Gerar resposta \n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", max_length=2048, truncation=True)\n",
    "    outputs = model.generate(**inputs, max_new_tokens=200, temperature=0.7)\n",
    "    resposta = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    return resposta.split(\"Resposta:\")[-1].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:100001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Com base nas informaç�es abaixo, responda à pergunta:\n",
      "\n",
      "    Contextos:\n",
      "    Contexto geral de episódios: As Tasmania Kid and Bighorn wander through a field beside the Yukikaze, Kid plucks a flower from the ground and shows it to Bighorn, commenting that he thinks the whole field is a bit on the gaudy side. The red hue of flower sends the pent-up Bighorn into a rage, and he repeatedly headbutts a rock wall as he roars about the current lack of action. Meanwhile, aboard the ship, Apache and NAVI report to Lio Convoy that they are unable to get a fix on the Destrons' ship. Lio Convoy arranges for an on-foot search of the planet, and Scuba and Diver go outside to inform Kid and Bighorn. Bighorn roars with delight and immediately stampedes off, followed by Kid; Diver turns to suggest that he and Scuba go in the opposite direction, but Scuba has already gone off on his own. Elsewhere, aboard the Galvaburg II, with Galvatron still unconscious after his experience with the ancient Gaean computer, Megastorm continues to command the Predacons toward his own ends. Megastorm instructs the Combatrons to find Lio Convoy, to merely report his location, so that he can destroy the Maximal leader himself. The four jets head out, and Starscream and BB soon come across Bighorn and Tasmania Kid in a forest. Bighorn takes offense when they try to ignore him and go on with their mission, so BB distracts him with a barrage of bombs so that they can go on their way. Up in the Moon, Artemis watches the whole thing, agreeing that Bighorn is right to be so annoyed after being ignored. Somewhere nearby, Thrust and Dirge have taken Megastorm's mission less than seriously, and are sitting around complaining about him when Bighorn comes charging towards them. They sidestep his charge, realising that he can't turn very well, but once he transforms to robot mode, a hail of missiles suddenly comes streaming down out of the sky, collapsing a cliff on top of all three of them. This is, of course, Starscream and BB's doing: they're out to take Thrust and Dirge out of the running and get all the credit for finding Lio Convoy, and they fly off before Bighorn can dig himself out. Emerging from the rubble, Bullhorn is met only by the sight of Kid, teasing him that once again, the bad guys have left before he can fight them. Ultimately, it is Diver who strikes it lucky, coming across the Galvaburg II berthed in a crevasse. As he radios in his discovery, Megastorm emerges from the craft to search out Lio Convoy himself, and immediately spots Diver hiding behind some rocks. Diver flees as Megastorm opens fire, but the Destron pursues, seeking to capture the Cybertron and force Lio Convoy's location from him. Diver radios for help, and his transmission is picked up by Kid and Bighorn (who has been busy plucking flower petals to see if he can or cannot go on a rampage). The pair quickly arrive to help Diver, and Bighorn body-slams Megastorm, who is not especially happy that he's being confronted with minions, instead of Lio Convoy himself. Starscream and BB show up and are ordered by Megastorm to deal with Bighorn, but the fighting-mad Cybertron takes them both down by returning the favour and collapsing a cliff on them. Enraged, Megastorm transforms to tank mode and prepares to fire his cannon, but it takes so long to charge that Bighorn is able to slam into him before he can open fire. Megastorm is content to weather the beating and wait, and once his cannon reaches full charge, the blast tears up the surrounding landscape, with even a glancing blow sending Bighorn flying off into the distance. Lio Convoy and Apache arrive as the smoke clears, and Lio Convoy tells Bighorn that he can stand down, but Bighorn refuses. BB and Starscream burst out from under the rocks and try to take on Lio Convoy, but with a little help from Apache, he takes them both down, leaving Bighorn to face off with Megastorm again. Bighorn calls out to Kid to give him a hand, instructing him to pull on his tail. Kid is confused, but as Megastorm's cannon nears full charge again, Bighorn insists, and Kid complies. Tugging on Bighorn's tail activates his special ability, the \"Buffalo Missile\", which blasts Megastorm off into the sky. As the injured Destrons escape aboard the Galvaburg II, Bighorn sighs with relief, and announces that he feels relaxed now. A little later, back in the field by the Yukikaze, Diver shows Tasmania Kid a flower that he plans to give Bighorn as a little reward for such a great fight. Before Kid can stop him, Bullhorn spots the red flower from a distance, and comes roaring towards them...! (Source: Transformers Wiki)\n",
      "Leaving behind Don Patch for the moment, Bo-bobo and Beauty first head to a Wig-Out Festival, where we discover the value of giant burger costumes and why dynamite should never play the stock market. Then, the duo encounter a hair hunter with a weird taste in underwear, considering there's a duck sticking out of the front of it! (Source: Wikipedia)\n",
      "\n",
      "    Pergunta: sinopse de cowboy bebop\n",
      "\n",
      "    Resposta (use markdown para destacar títulos):\n",
      "    \n",
      "1. Gênese do Universo: A história começa no tempo primordial, quando a Força Primordial criou o Universo a partir da nada. Existem várias vers�es da criação do Universo na ficção, incluindo o Big Bang e a criação por uma entidade superior.\n",
      "2. Vida Inicial: Depois da criação do Universo, surgiram as primeiras formas de vida. Alguns destes primeiros seres viveram durante milh�es de anos, enquanto outros se extinguiram devido a perigos naturais ou mutaç�es genéticas.\n",
      "3. Evolução: As primeiras formas de vida evoluíram em seres mais complexos, como organismos unicelulares e organismos multicelulares. Esses seres evoluíram\n"
     ]
    }
   ],
   "source": [
    "resposta = gerar_respostaComVetorEpisodios(\"cowboy bebop\")\n",
    "print(resposta)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "raganime",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

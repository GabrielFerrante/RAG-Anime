{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "from easyocr import Reader\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import pickle  \n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "reader = Reader(['pt'], gpu=True, verbose=False, download_enabled=True, recognizer=True)  # Altere conforme o idioma do mangá\n",
    "\n",
    "def preprocess_image(img_array):\n",
    "    \"\"\"Aplica pré-processamento para melhorar a detecção de texto\"\"\"\n",
    "    # Conversão para escala de cinza\n",
    "    gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    # Redução de ruído com filtro bilateral (preserva bordas)\n",
    "    denoised = cv2.bilateralFilter(gray, 9, 75, 75)\n",
    "    \n",
    "    # Equalização de histograma adaptativo para melhorar contraste\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    contrast_enhanced = clahe.apply(denoised)\n",
    "    \n",
    "    # Binarização adaptativa para lidar com variações de iluminação\n",
    "    thresh = cv2.adaptiveThreshold(contrast_enhanced, 255, \n",
    "                                  cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                  cv2.THRESH_BINARY, 11, 2)\n",
    "    \n",
    "    # Operação morfológica para fechar pequenas lacunas no texto\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2,2))\n",
    "    processed = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n",
    "    \n",
    "    # Inversão de cores se necessário (para texto claro em fundo escuro)\n",
    "    if np.mean(processed) < 127:\n",
    "        processed = cv2.bitwise_not(processed)\n",
    "    \n",
    "    return cv2.cvtColor(processed, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "def process_page(page):\n",
    "    \"\"\"Processa uma única página com pré-processamento e EasyOCR\"\"\"\n",
    "    pix = page.get_pixmap()\n",
    "    img_array = np.frombuffer(pix.samples, dtype=np.uint8).reshape((pix.height, pix.width, 3))\n",
    "    \n",
    "    # Aplica pré-processamento\n",
    "    img_processed = preprocess_image(img_array)\n",
    "    \n",
    "    # Detecção de texto com ajustes para mangás\n",
    "    results = reader.readtext(img_processed,\n",
    "                             paragraph=True,\n",
    "                             text_threshold=0.4,\n",
    "                             link_threshold=0.4,\n",
    "                             rotation_info=[90, 180, 270])\n",
    "    \n",
    "    return \" \".join([result[1] for result in results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_text_with_easyocr(pdf_path, numberFile):\n",
    "    \"\"\"Processa PDF em batches para otimizar memória.\"\"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = []\n",
    "    pages = [doc.load_page(i) for i in range(len(doc))]\n",
    "    \n",
    "    for i in range(0, len(pages)):\n",
    "        batch_text = process_page(pages[i])\n",
    "        text.extend(batch_text)\n",
    "    with open(os.path.join(\"C:/Repositorios/RAG-Anime/onePiecePickles\", f\"{numberFile}.pkl\"), \"wb\") as f:\n",
    "        pickle.dump(text, f)       \n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      | 196503 KiB | 196503 KiB | 212951 KiB |  16448 KiB |\n",
      "|       from large pool | 184592 KiB | 184592 KiB | 192816 KiB |   8224 KiB |\n",
      "|       from small pool |  11911 KiB |  11911 KiB |  20135 KiB |   8224 KiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         | 196503 KiB | 196503 KiB | 212951 KiB |  16448 KiB |\n",
      "|       from large pool | 184592 KiB | 184592 KiB | 192816 KiB |   8224 KiB |\n",
      "|       from small pool |  11911 KiB |  11911 KiB |  20135 KiB |   8224 KiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Requested memory      | 192411 KiB | 192411 KiB | 208859 KiB |  16448 KiB |\n",
      "|       from large pool | 180544 KiB | 180544 KiB | 188768 KiB |   8224 KiB |\n",
      "|       from small pool |  11867 KiB |  11867 KiB |  20091 KiB |   8224 KiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   | 212992 KiB | 212992 KiB | 212992 KiB |      0 B   |\n",
      "|       from large pool | 200704 KiB | 200704 KiB | 200704 KiB |      0 B   |\n",
      "|       from small pool |  12288 KiB |  12288 KiB |  12288 KiB |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |  16489 KiB |  23413 KiB | 138728 KiB | 122239 KiB |\n",
      "|       from large pool |  16112 KiB |  22272 KiB | 120720 KiB | 104608 KiB |\n",
      "|       from small pool |    377 KiB |   2047 KiB |  18008 KiB |  17631 KiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |     368    |     368    |     386    |      18    |\n",
      "|       from large pool |      34    |      34    |      36    |       2    |\n",
      "|       from small pool |     334    |     334    |     350    |      16    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |     368    |     368    |     386    |      18    |\n",
      "|       from large pool |      34    |      34    |      36    |       2    |\n",
      "|       from small pool |     334    |     334    |     350    |      16    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |      16    |      16    |      16    |       0    |\n",
      "|       from large pool |      10    |      10    |      10    |       0    |\n",
      "|       from small pool |       6    |       6    |       6    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       6    |       6    |      26    |      20    |\n",
      "|       from large pool |       3    |       4    |      10    |       7    |\n",
      "|       from small pool |       3    |       3    |      16    |      13    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.memory_summary())\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      | 196503 KiB | 196503 KiB | 212951 KiB |  16448 KiB |\n",
      "|       from large pool | 184592 KiB | 184592 KiB | 192816 KiB |   8224 KiB |\n",
      "|       from small pool |  11911 KiB |  11911 KiB |  20135 KiB |   8224 KiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         | 196503 KiB | 196503 KiB | 212951 KiB |  16448 KiB |\n",
      "|       from large pool | 184592 KiB | 184592 KiB | 192816 KiB |   8224 KiB |\n",
      "|       from small pool |  11911 KiB |  11911 KiB |  20135 KiB |   8224 KiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Requested memory      | 192411 KiB | 192411 KiB | 208859 KiB |  16448 KiB |\n",
      "|       from large pool | 180544 KiB | 180544 KiB | 188768 KiB |   8224 KiB |\n",
      "|       from small pool |  11867 KiB |  11867 KiB |  20091 KiB |   8224 KiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   | 212992 KiB | 212992 KiB | 212992 KiB |      0 B   |\n",
      "|       from large pool | 200704 KiB | 200704 KiB | 200704 KiB |      0 B   |\n",
      "|       from small pool |  12288 KiB |  12288 KiB |  12288 KiB |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |  16489 KiB |  23413 KiB | 138728 KiB | 122239 KiB |\n",
      "|       from large pool |  16112 KiB |  22272 KiB | 120720 KiB | 104608 KiB |\n",
      "|       from small pool |    377 KiB |   2047 KiB |  18008 KiB |  17631 KiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |     368    |     368    |     386    |      18    |\n",
      "|       from large pool |      34    |      34    |      36    |       2    |\n",
      "|       from small pool |     334    |     334    |     350    |      16    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |     368    |     368    |     386    |      18    |\n",
      "|       from large pool |      34    |      34    |      36    |       2    |\n",
      "|       from small pool |     334    |     334    |     350    |      16    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |      16    |      16    |      16    |       0    |\n",
      "|       from large pool |      10    |      10    |      10    |       0    |\n",
      "|       from small pool |       6    |       6    |       6    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       6    |       6    |      26    |      20    |\n",
      "|       from large pool |       3    |       4    |      10    |       7    |\n",
      "|       from small pool |       3    |       3    |      16    |      13    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.memory_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finalizado One Piece Vol.01.pdf\n",
      "Finalizado One Piece Vol.02.pdf\n",
      "Finalizado One Piece Vol.03.pdf\n",
      "Finalizado One Piece Vol.04.pdf\n",
      "Finalizado One Piece Vol.05.pdf\n",
      "Finalizado One Piece Vol.06.pdf\n",
      "Finalizado One Piece Vol.07.pdf\n",
      "Finalizado One Piece Vol.08.pdf\n",
      "Finalizado One Piece Vol.09.pdf\n",
      "Finalizado One Piece Vol.10.pdf\n",
      "Finalizado One Piece Vol.101.pdf\n",
      "Finalizado One Piece Vol.102.pdf\n",
      "Finalizado One Piece Vol.103.pdf\n",
      "Finalizado One Piece Vol.104.pdf\n",
      "Finalizado One Piece Vol.105.pdf\n",
      "Finalizado One Piece Vol.106.pdf\n",
      "Finalizado One Piece Vol.107.pdf\n",
      "Finalizado One Piece Vol.108.pdf\n",
      "Finalizado One Piece Vol.109.pdf\n",
      "Finalizado One Piece Vol.110.pdf\n",
      "Finalizado One Piece Vol.11.pdf\n",
      "Finalizado One Piece Vol.12.pdf\n",
      "Finalizado One Piece Vol.13.pdf\n",
      "Finalizado One Piece Vol.14.pdf\n",
      "Finalizado One Piece Vol.15.pdf\n",
      "Finalizado One Piece Vol.16.pdf\n",
      "Finalizado One Piece Vol.17.pdf\n",
      "Finalizado One Piece Vol.18.pdf\n",
      "Finalizado One Piece Vol.19.pdf\n",
      "Finalizado One Piece Vol.20.pdf\n",
      "Finalizado One Piece Vol.111.pdf\n",
      "Finalizado One Piece Vol.21.pdf\n",
      "Finalizado One Piece Vol.22.pdf\n",
      "Finalizado One Piece Vol.23.pdf\n",
      "Finalizado One Piece Vol.24.pdf\n",
      "Finalizado One Piece Vol.25.pdf\n",
      "Finalizado One Piece Vol.26.pdf\n",
      "Finalizado One Piece Vol.27.pdf\n",
      "Finalizado One Piece Vol.28.pdf\n",
      "Finalizado One Piece Vol.29.pdf\n",
      "Finalizado One Piece Vol.30.pdf\n",
      "Finalizado One Piece Vol.31.pdf\n",
      "Finalizado One Piece Vol.32.pdf\n",
      "Finalizado One Piece Vol.33.pdf\n",
      "Finalizado One Piece Vol.34.pdf\n",
      "Finalizado One Piece Vol.35.pdf\n",
      "Finalizado One Piece Vol.36.pdf\n",
      "Finalizado One Piece Vol.37.pdf\n",
      "Finalizado One Piece Vol.38.pdf\n",
      "Finalizado One Piece Vol.39.pdf\n",
      "Finalizado One Piece Vol.40.pdf\n",
      "Finalizado One Piece Vol.41.pdf\n",
      "Finalizado One Piece Vol.42.pdf\n",
      "Finalizado One Piece Vol.43.pdf\n",
      "Finalizado One Piece Vol.44.pdf\n",
      "Finalizado One Piece Vol.45.pdf\n",
      "Finalizado One Piece Vol.46.pdf\n",
      "Finalizado One Piece Vol.47.pdf\n",
      "Finalizado One Piece Vol.48.pdf\n",
      "Finalizado One Piece Vol.49.pdf\n",
      "Finalizado One Piece Vol.50.pdf\n",
      "Finalizado One Piece Vol.51.pdf\n",
      "Finalizado One Piece Vol.52.pdf\n",
      "Finalizado One Piece Vol.53.pdf\n",
      "Finalizado One Piece Vol.54.pdf\n",
      "Finalizado One Piece Vol.55.pdf\n",
      "Finalizado One Piece Vol.56.pdf\n",
      "Finalizado One Piece Vol.57.pdf\n",
      "Finalizado One Piece Vol.58.pdf\n",
      "Finalizado One Piece Vol.59.pdf\n",
      "Finalizado One Piece Vol.60.pdf\n",
      "Finalizado One Piece Vol.61.pdf\n",
      "Finalizado One Piece Vol.62.pdf\n",
      "Finalizado One Piece Vol.63.pdf\n",
      "Finalizado One Piece Vol.64.pdf\n",
      "Finalizado One Piece Vol.65.pdf\n",
      "Finalizado One Piece Vol.66.pdf\n",
      "Finalizado One Piece Vol.67.pdf\n",
      "Finalizado One Piece Vol.68.pdf\n",
      "Finalizado One Piece Vol.69.pdf\n",
      "Finalizado One Piece Vol.70.pdf\n",
      "Finalizado One Piece Vol.71.pdf\n",
      "Finalizado One Piece Vol.72.pdf\n",
      "Finalizado One Piece Vol.73.pdf\n",
      "Finalizado One Piece Vol.74.pdf\n",
      "Finalizado One Piece Vol.75.pdf\n",
      "Finalizado One Piece Vol.76.pdf\n",
      "Finalizado One Piece Vol.77.pdf\n",
      "Finalizado One Piece Vol.78.pdf\n",
      "Finalizado One Piece Vol.79.pdf\n",
      "Finalizado One Piece Vol.80.pdf\n",
      "Finalizado One Piece Vol.81.pdf\n",
      "Finalizado One Piece Vol.82.pdf\n",
      "Finalizado One Piece Vol.83.pdf\n",
      "Finalizado One Piece Vol.84.pdf\n",
      "Finalizado One Piece Vol.85.pdf\n",
      "Finalizado One Piece Vol.86.pdf\n",
      "Finalizado One Piece Vol.87.pdf\n",
      "Finalizado One Piece Vol.88.pdf\n",
      "Finalizado One Piece Vol.89.pdf\n",
      "Finalizado One Piece Vol.90.pdf\n",
      "Finalizado One Piece Vol.100.pdf\n",
      "Finalizado One Piece Vol.91.pdf\n",
      "Finalizado One Piece Vol.92.pdf\n",
      "Finalizado One Piece Vol.93.pdf\n",
      "Finalizado One Piece Vol.94.pdf\n",
      "Finalizado One Piece Vol.95.pdf\n",
      "Finalizado One Piece Vol.96.pdf\n",
      "Finalizado One Piece Vol.97.pdf\n",
      "Finalizado One Piece Vol.98.pdf\n",
      "Finalizado One Piece Vol.99.pdf\n"
     ]
    }
   ],
   "source": [
    "\n",
    "files = os.listdir('E:/One Piece Manga/')\n",
    "for folder in files:\n",
    "    if not folder.endswith('.pdf'):\n",
    "        filesPDF = os.listdir(f'E:/One Piece Manga/{folder}/{folder}/')\n",
    "        for pdf in filesPDF:\n",
    "            extract_text_with_easyocr(f'E:/One Piece Manga/{folder}/{folder}/' + pdf, pdf.split(\".\")[1])\n",
    "            print(f\"Finalizado {pdf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name neuralmind/bert-base-portuguese-cased. Creating a new one with mean pooling.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings  # Altere conforme necessário\n",
    "\n",
    "# 1. Configuração do Text Splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=50,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    ")\n",
    "\n",
    "# 2. Configuração do Modelo de Embedding (exemplo com HuggingFace)\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=\"neuralmind/bert-base-portuguese-cased\",  # Altere para o modelo desejado\n",
    "    model_kwargs={'device': 'cuda'},  # ou 'cpu' se não tiver GPU\n",
    "    encode_kwargs={'normalize_embeddings': False}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_volumes(pickle_dir, output_dir=\"embeddingsOnePiece\"):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    all_chunks = []\n",
    "    \n",
    "    # Processar cada arquivo pickle\n",
    "    for filename in os.listdir(pickle_dir):\n",
    "        if filename.endswith(\".pkl\"):\n",
    "            volume_path = os.path.join(pickle_dir, filename)\n",
    "            \n",
    "            # Carregar o texto\n",
    "            with open(volume_path, \"rb\") as f:\n",
    "                volume_text = pickle.load(f)\n",
    "            \n",
    "            # Converter lista para string se necessário\n",
    "            if isinstance(volume_text, list):\n",
    "                volume_text = \" \".join(volume_text)  # Concatena todos os elementos da lista\n",
    "                \n",
    "            # Aplicar split de texto\n",
    "            chunks = text_splitter.split_text(volume_text)\n",
    "            \n",
    "            # Gerar embeddings para cada chunk\n",
    "            volume_embeddings = embedding_model.embed_documents(chunks)\n",
    "            \n",
    "            # Salvar resultados\n",
    "            output_data = {\n",
    "                'volume_name': filename,\n",
    "                'chunks': chunks,\n",
    "                'embeddings': volume_embeddings\n",
    "            }\n",
    "            \n",
    "            output_path = os.path.join(output_dir, f\"embeddings_{filename}\")\n",
    "            with open(output_path, \"wb\") as f:\n",
    "                pickle.dump(output_data, f)\n",
    "            \n",
    "            all_chunks.extend(zip(chunks, volume_embeddings))\n",
    "    \n",
    "    return all_chunks\n",
    "\n",
    "# 4. Executar o processamento\n",
    "volumes_dir = \"C:/Repositorios/RAG-Anime/onePiecePickles\"  # Altere para seu diretório\n",
    "resultado_embeddings = process_volumes(volumes_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS  # Exemplo com FAISS\n",
    "\n",
    "# Criar vetorstore\n",
    "vectorstore = FAISS.from_texts(\n",
    "    texts=[chunk[0] for chunk in resultado_embeddings],\n",
    "    embedding=embedding_model,\n",
    "    metadatas=[{\"volume\": chunk[1]} for chunk in resultado_embeddings]\n",
    ")\n",
    "\n",
    "# Salvar para uso futuro\n",
    "vectorstore.save_local(\"one_piece_faiss_index\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "raganime",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

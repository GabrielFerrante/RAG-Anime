{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from processData.AnimeRequest import generateDataFramePersonagens, generateDataFrameAnimes, generateDataFrameEpisodios\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir('./dados/')\n",
    "\n",
    "listaDePersonagens = []\n",
    "animesEpisodios = []\n",
    "\n",
    "for file in files:\n",
    "    if file.endswith('.json'):\n",
    "        if file.startswith('personagensAnimes'):\n",
    "            listaDePersonagens.append(file)\n",
    "        if file.startswith('episodios-'):\n",
    "            animesEpisodios.append(file)\n",
    "\n",
    "print(listaDePersonagens)\n",
    "print(len(listaDePersonagens))\n",
    "print(animesEpisodios)\n",
    "print(len(animesEpisodios))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = generateDataFrameAnimes('C:/Repositorios/RAG-Anime/dados/animes.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[0].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[0].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando os dataframes\n",
    "dataFramePersonagens = []\n",
    "for i in range(0, len(listaDePersonagens)):\n",
    "    dataFramePersonagens.append(generateDataFramePersonagens(f'./dados/{listaDePersonagens[i]}'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFramePersonagens[0][0].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFramePersonagens[0][0]['character.name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir sinopses em chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=400,\n",
    "    chunk_overlap=50,\n",
    "    separators=[\"\\n\", \"。\", \".\"]  # Adaptado para frases\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunksAnimes = []\n",
    "print(len(df))\n",
    "for i in range(0, 213):\n",
    "    for index, row in df[i].iterrows():\n",
    "        if row[\"synopsis\"] != None:\n",
    "            synopsis_chunks = text_splitter.split_text(row[\"synopsis\"])\n",
    "            print(synopsis_chunks)\n",
    "            for chunk in synopsis_chunks:\n",
    "                chunksAnimes.append({\n",
    "                    \"text\": chunk,\n",
    "                    \"title\": row[\"title\"],\n",
    "                    \"episodes\": row[\"episodes\"],\n",
    "                    \"year\": row[\"year\"],\n",
    "                    \"mal_id\": row[\"mal_id\"],\n",
    "                    'type': row['type'],\n",
    "                    'status': row['status'],\n",
    "                    'studios': row['studios'],\n",
    "\n",
    "                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunksPersonagens = []\n",
    "\n",
    "for i in range(0, len(listaDePersonagens)):\n",
    "    for item in dataFramePersonagens[i]:\n",
    "        for index, row in item.iterrows():\n",
    "            print(item['character.name'])\n",
    "            names_chunks = text_splitter.split_text(row[\"character.name\"])\n",
    "            print(names_chunks)\n",
    "            for chunk in names_chunks:\n",
    "                chunksPersonagens.append({\n",
    "                        \"text\": chunk,\n",
    "                        \"role\": row[\"role\"],\n",
    "                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extrair textos e metadados para o FAISS\n",
    "texts = [chunk[\"text\"] for chunk in chunksAnimes]\n",
    "metadatas = [{\n",
    "    \"title\": chunk[\"title\"],\n",
    "      \"episodes\": chunk[\"episodes\"], \n",
    "      \"year\": chunk[\"year\"], \n",
    "      'mal_id': chunk['mal_id'], \n",
    "      'type': chunk['type'], \n",
    "      'status': chunk['status'], \n",
    "      'studios': chunk['studios']} for chunk in chunksAnimes]\n",
    "\n",
    "\n",
    "textsPersonagens = [chunk[\"text\"] for chunk in chunksPersonagens]\n",
    "metadatasPersonagens = [{\n",
    "    'role': chunk['role'],\n",
    "      } for chunk in chunksPersonagens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerar embeddings (modelo multilíngue)\n",
    "embeddingsAnimes = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\"\n",
    ")\n",
    "\n",
    "# Armazenar no FAISS\n",
    "vector_dbAnimes = FAISS.from_texts(\n",
    "    texts,\n",
    "    embeddingsAnimes,\n",
    "    metadatas=metadatas\n",
    ")\n",
    "\n",
    "# Salvar o índice\n",
    "vector_dbAnimes.save_local(\"animes_faiss_index\")\n",
    "\n",
    "\n",
    "\n",
    "# Armazenar no FAISS\n",
    "vector_dbPersonagens = FAISS.from_texts(\n",
    "    textsPersonagens,\n",
    "    embeddingsAnimes,\n",
    "    metadatas=metadatasPersonagens\n",
    ")\n",
    "\n",
    "# Salvar o índice\n",
    "vector_dbAnimes.save_local(\"personagens_faiss_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando os dataframes\n",
    "dataFrameEpisodios = []\n",
    "idsAnimes = []\n",
    "for i in range(0, len(animesEpisodios)):\n",
    "    episodios, id = generateDataFrameEpisodios(f'./dados/{animesEpisodios[i]}')\n",
    "    dataFrameEpisodios.append(episodios)\n",
    "    idsAnimes.append(id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFrameEpisodios[0][0].info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFrameEpisodios[0][0]['data'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunksEpisodios = []\n",
    "\n",
    "for i in range(0, len(animesEpisodios)):\n",
    "    for item in dataFrameEpisodios[i]:\n",
    "        print(item['data'].keys())\n",
    "        for index, row in item.iterrows():\n",
    "            if 'error' not in row.keys():\n",
    "                print(row['data'])\n",
    "                names_chunks = text_splitter.split_text(str(idsAnimes[i]))\n",
    "                #if row['data']['title'] != None and row['data']['synopsis'] != None and row['data']['duration'] != None and row['data']['filler'] != None:\n",
    "                for chunk in names_chunks:\n",
    "                    chunksEpisodios.append({\n",
    "                                \"animeId\": chunk,\n",
    "                                \"numeroEpisodio\": str(row['data']['mal_id']),\n",
    "                                'title': str(row['data']['title']),\n",
    "                                'duration': str(row['data']['duration']),\n",
    "                                'synopsis': str(row['data']['synopsis']),\n",
    "                                'filler': str(row['data']['filler']),\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunksEpisodios[30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extrair textos e metadados para o FAISS\n",
    "textsEpisodios = [chunk[\"synopsis\"] for chunk in chunksEpisodios]\n",
    "metadatasEpisodios = [{\n",
    "    \"numeroEpisodio\": chunk['numeroEpisodio'],\n",
    "    'title': chunk['title'],\n",
    "    'duration': chunk['duration'],\n",
    "    'filler': chunk['filler'],} for chunk in chunksEpisodios]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Armazenar no FAISS\n",
    "vector_dbEpisodios = FAISS.from_texts(\n",
    "    textsEpisodios,\n",
    "    embeddingsAnimes,\n",
    "    metadatas=metadatasEpisodios\n",
    ")\n",
    "\n",
    "# Salvar o índice\n",
    "vector_dbEpisodios.save_local(\"episodios_faiss_index\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "raganime",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
